== What is this app?

This app is used to run throughput performance tests on Spring Cloud Stream consumer against the Kafka binder.

It allows the testing of two different usage patterns of StreamListener (one is a delcarative approach where we declaratively handle the input message and the other one is a non declarative approach which means that on each message arrival at the input channnel, target method arguments are resolved and then invoke the method)

==== Before running the app, make sure that you have Kafka environment up and running. Use one of the following methods

1. You can use a local Kafka cluster (single node clusters are enough)
2. Or a Kafka cluster somewhere on powerful servers or platforms (GCP, AWS, Rackspace etc.)
3. Or you can also run Kafka inside a docker ennvironment. For this, go to the docker directory in this repo and invoke the command `docker-compose up -d`.
   
Once you have a kafka environment, do the following.

1. Go to your kafka home. If you are using the docker images, invoke the script `start-kafka-shell.sh` and then `cd $KAFKA_HOME`.

Note: If you are using Docker images, zookeeper-ip below is `localhost` on linux or `192.168.99.100` on mac osx.

2. `bin/kafka-topics.sh --zookeeper <zookeeper-ip>:2181 --create --topic foobar --partitions 3 --replication-factor 1`
3. `bin/kafka-topics.sh --zookeeper <zookeeper-ip>:2181 --describe foobar`

4. Pre-load 1 million messages with 1K size:

`bin/kafka-producer-perf-test.sh --num-records 1000000 --record-size 1024 --producer-props bootstrap.servers=<kafka-broker>:9092 zk.connect=<zoo-keeper>:2181 batch.size=100  --throughput 100000 --topic foobar`

=== Running the sample app:

Go to the root of the repository and do: `./mvnw clean package`

=== Explanation of the custom properties

`num.messages` - messages to consume

`print.on.every` - Print a message with the current count consumed

`non-declarative` - invoking the non-declarative stream listener

`declarative` - invoking the declarative stream listener`

The following 2 properties can be used when running multiple consumers. This would effectively track the progress of the message consumption across the consumers. Basically, uses a scheduled task internally to see if we stopeed consuming for a duration. If so, determines that the consumer is done.

`multi.consumer.non.declarative=true` 

`multi.consumer.declarative=true` 

==== Running non-declarative StreamListener in a single consumer mode that consumes 1 million messages and prints every 10K messages:

`java -jar scst-kafka-perf-0.0.1-SNAPSHOT.jar --spring.cloud.stream.kafka.binder.brokers=192.168.99.100 --spring.cloud.stream.kafka.binder.zkNodes=192.168.99.100 --non.declarative=true --num.messages=1000000 --print.on.every=10000 --spring.cloud.stream.bindings.input.destination=foobar --spring.kafka.consumer.groupId=foobar-1`

==== Running declarative StreamListener in a single consumer mode that consumes 1 million messages and prints every 10K messages:

`java -jar scst-kafka-perf-0.0.1-SNAPSHOT.jar --spring.cloud.stream.kafka.binder.brokers=192.168.99.100 --spring.cloud.stream.kafka.binder.zkNodes=192.168.99.100 --declarative=true --num.messages=1000000 --print.on.every=10000 --spring.cloud.stream.bindings.input.destination=foobar --spring.kafka.consumer.groupId=foobar-1`

